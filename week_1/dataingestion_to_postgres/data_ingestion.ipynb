{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the parquet file to csv, will see why in following codes\n",
    "pd.read_parquet(\"/Users/ashwinkadam/yellow_tripdata_2022-01 (1).parquet\", engine = \"pyarrow\").to_csv(\"/Users/ashwinkadam/yellow_tripdata_2022-01\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinkadam/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"y_taxi\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"passenger_count\" REAL,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"RatecodeID\" REAL,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"congestion_surcharge\" REAL,\n",
      "  \"airport_fee\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#lets read csv\n",
    "df = pd.read_csv(\"/Users/ashwinkadam/yellow_tripdata_2022-01\")\n",
    "\n",
    "#generating schema for database \n",
    "#print(pd.io.sql.get_schema(df, name=\"yellow_taxi_data\"))\n",
    "\n",
    "#we see that some columns datatype is misleading.\n",
    "#the reason for this wrong datatype is that the csv file doesn't store datetime format like parquet file.\n",
    "#before we load the schema in database lets correct them.\n",
    "\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "print(pd.io.sql.get_schema(df, name=\"y_taxi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7f95daecc580>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets create connection between and SQL/database and python\n",
    "# postgresql://username:password@localhost:port/dbname\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we connection lets push the data in postgres, but will push in chunks. less memory utilization.\n",
    "# we converted parquet to csv to use chunk_size function , very handy.\n",
    "# first will add the first chunk then will iterate in loop untill we ingest all.\n",
    "\n",
    "df_iter = pd.read_csv(\"/Users/ashwinkadam/yellow_tripdata_2022-01\", iterator=True, chunksize=100000)\n",
    "\n",
    "df = next(df_iter)\n",
    "\n",
    "df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "df.head(n=0).to_sql(name=\"y_taxi\",index = False,  con=engine, if_exists='replace')\n",
    "\n",
    "df.to_sql(name=\"y_taxi\", index = False, con=engine, if_exists='append')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 83.076 second\n",
      "inserted another chunk, took 81.308 second\n",
      "inserted another chunk, took 80.842 second\n",
      "inserted another chunk, took 82.848 second\n",
      "inserted another chunk, took 83.045 second\n",
      "inserted another chunk, took 84.744 second\n",
      "inserted another chunk, took 81.717 second\n",
      "inserted another chunk, took 82.672 second\n",
      "inserted another chunk, took 83.569 second\n",
      "inserted another chunk, took 82.857 second\n",
      "inserted another chunk, took 82.171 second\n",
      "inserted another chunk, took 85.809 second\n",
      "inserted another chunk, took 85.967 second\n",
      "inserted another chunk, took 6962.048 second\n",
      "inserted another chunk, took 16939.880 second\n",
      "inserted another chunk, took 7835.731 second\n",
      "inserted another chunk, took 84.475 second\n",
      "inserted another chunk, took 89.233 second\n",
      "inserted another chunk, took 86.274 second\n",
      "inserted another chunk, took 90.398 second\n",
      "inserted another chunk, took 92.267 second\n",
      "inserted another chunk, took 83.252 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinkadam/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 91.687 second\n",
      "inserted another chunk, took 53.947 second\n",
      "Finished ingesting data into the postgres database\n"
     ]
    }
   ],
   "source": [
    "# Iteration to ingest rest of the data\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        t_start = time()\n",
    "\n",
    "        df = next(df_iter)\n",
    "\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "\n",
    "        df.to_sql(\"y_taxi\", index = False, con=engine, if_exists='append')\n",
    "\n",
    "        t_end = time()\n",
    "\n",
    "        print('inserted another chunk, took %.3f second' %\n",
    "        (t_end - t_start))\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"Finished ingesting data into the postgres database\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e93adadf35716784c5be3804e27c1b328c40db1e555eceb264c98c6b95e32ec4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
